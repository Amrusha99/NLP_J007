{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amrusha99/NLP_J007/blob/master/nlp_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlwrrbu97BWQ",
        "colab_type": "code",
        "outputId": "cec55304-24ca-4675-8b56-b52d4cc21f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4T3ywJu8NvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\", lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAr8nxyG8aSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using word_tokenizer\n",
        "def word_tokenizer(str):\n",
        "  tokens=dict()\n",
        "  txt = re.sub(r'[^\\w\\s]','',str)\n",
        "  tokens[\"Word_tokens\"]=nltk.word_tokenize(txt)\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_Tp76Dv4-4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "de3958b4-8cb9-459b-ad19-7921f382bff7"
      },
      "source": [
        "#Applying word_tokenize on 20th row of reviewText\n",
        "tkns=word_tokenizer(df.reviewText[20])\n",
        "print(tkns)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Word_tokens': ['This', 'calculator', 'does', 'the', 'job', 'for', 'what', 'I', 'need', 'No', 'batteries', 'needed', 'and', 'it', 'is', 'solar', 'powered', 'Only', 'problem', 'I', 'have', 'is', 'the', 'cover', 'case', 'It', 'is', 'not', 'slide', 'in', 'slide', 'out', 'cover', 'cases', 'like', 'most', 'calculators', 'It', 'is', 'more', 'of', 'a', 'snap', 'it', 'on', 'snap', 'it', 'off', 'Other', 'than', 'that', 'it', 'does', 'help', 'protect', 'it', 'from', 'dust', 'and', 'getting', 'the', 'screen', 'scratched']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGiBN0LSAyzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "d54c115b-36f0-4a06-a859-0b847eb76f92"
      },
      "source": [
        "#Applying word_tokenize on complete reviewText\n",
        "df[\"reviewText_word_tokenizer\"]=df.reviewText.apply(word_tokenizer)\n",
        "print(df[\"reviewText_word_tokenizer\"])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        {'Word_tokens': ['I', 'bought', 'my', 'first',...\n",
            "1        {'Word_tokens': ['WHY', 'THIS', 'BELATED', 'RE...\n",
            "2        {'Word_tokens': ['I', 'have', 'an', 'HP', '48G...\n",
            "3        {'Word_tokens': ['Ive', 'started', 'doing', 'm...\n",
            "4        {'Word_tokens': ['For', 'simple', 'calculation...\n",
            "                               ...                        \n",
            "53253    {'Word_tokens': ['What', 'I', 'like', 'about',...\n",
            "53254    {'Word_tokens': ['This', 'Accuteck', 'ShipPro'...\n",
            "53255    {'Word_tokens': ['I', 'ship', 'a', 'lot', 'of'...\n",
            "53256    {'Word_tokens': ['This', 'is', 'a', 'great', '...\n",
            "53257    {'Word_tokens': ['When', 'asked', 'to', 'revie...\n",
            "Name: reviewText_word_tokenizer, Length: 53258, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsFLfwdPAzAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using MWE Tokenizer\n",
        "from nltk.tokenize import MWETokenizer\n",
        "def mwe_tokenizer(str):\n",
        "  mwe_dict=dict()\n",
        "  mwetokenizer = MWETokenizer()\n",
        "  mwe_dict[\"MWE_tokens\"]=mwetokenizer.tokenize(str.split())\n",
        "  return mwe_dict\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6-zUSEet3b4",
        "colab_type": "code",
        "outputId": "00e9c604-a798-464c-c005-72791b1dd19a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Applying word_tokenize on 20th row of reviewText\n",
        "mwe_tkns=mwe_tokenizer(df.reviewText[20])\n",
        "print(mwe_tkns)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'MWE_tokens': ['This', 'calculator', 'does', 'the', 'job', 'for', 'what', 'I', 'need.', 'No', 'batteries', 'needed', 'and', 'it', 'is', 'solar', 'powered.', 'Only', 'problem', 'I', 'have', 'is', 'the', 'cover', 'case.', 'It', 'is', 'not', 'slide', 'in', '/', 'slide', 'out', 'cover', 'cases', 'like', 'most', 'calculators.', 'It', 'is', 'more', 'of', 'a', 'snap', 'it', 'on', '/', 'snap', 'it', 'off.', 'Other', 'than', 'that', 'it', 'does', 'help', 'protect', 'it', 'from', 'dust', 'and', 'getting', 'the', 'screen', 'scratched.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFaQ81Spk38h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "9cd9a581-ad65-4a57-f135-7b1c9972216f"
      },
      "source": [
        "#Applying word_tokenize on complete reviewText\n",
        "df[\"reviewText_mwe_tokenizer\"]=df.reviewText.apply(mwe_tokenizer)\n",
        "print(df[\"reviewText_word_tokenizer\"])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        {'Word_tokens': ['I', 'bought', 'my', 'first',...\n",
            "1        {'Word_tokens': ['WHY', 'THIS', 'BELATED', 'RE...\n",
            "2        {'Word_tokens': ['I', 'have', 'an', 'HP', '48G...\n",
            "3        {'Word_tokens': ['Ive', 'started', 'doing', 'm...\n",
            "4        {'Word_tokens': ['For', 'simple', 'calculation...\n",
            "                               ...                        \n",
            "53253    {'Word_tokens': ['What', 'I', 'like', 'about',...\n",
            "53254    {'Word_tokens': ['This', 'Accuteck', 'ShipPro'...\n",
            "53255    {'Word_tokens': ['I', 'ship', 'a', 'lot', 'of'...\n",
            "53256    {'Word_tokens': ['This', 'is', 'a', 'great', '...\n",
            "53257    {'Word_tokens': ['When', 'asked', 'to', 'revie...\n",
            "Name: reviewText_word_tokenizer, Length: 53258, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN6uwZEX-bVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using pos_tag\n",
        "def postag(str):\n",
        "  pos_dict=dict()\n",
        "  pos_dict[\"POS_tags\"]=nltk.pos_tag(nltk.word_tokenize(str))\n",
        "  return pos_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJuGcOu2_g1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "8675c34d-5cb9-4a2b-e0e8-09f4c54c7755"
      },
      "source": [
        "#Applying postag on 20th row\n",
        "pos_t=postag(df.reviewText[20])\n",
        "print(pos_t)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'POS_tags': [('This', 'DT'), ('calculator', 'NN'), ('does', 'VBZ'), ('the', 'DT'), ('job', 'NN'), ('for', 'IN'), ('what', 'WP'), ('I', 'PRP'), ('need', 'VBP'), ('.', '.'), ('No', 'DT'), ('batteries', 'NNS'), ('needed', 'VBN'), ('and', 'CC'), ('it', 'PRP'), ('is', 'VBZ'), ('solar', 'JJ'), ('powered', 'VBN'), ('.', '.'), ('Only', 'RB'), ('problem', 'NN'), ('I', 'PRP'), ('have', 'VBP'), ('is', 'VBZ'), ('the', 'DT'), ('cover', 'NN'), ('case', 'NN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('not', 'RB'), ('slide', 'RB'), ('in', 'IN'), ('/', 'NNP'), ('slide', 'NN'), ('out', 'IN'), ('cover', 'NN'), ('cases', 'NNS'), ('like', 'IN'), ('most', 'JJS'), ('calculators', 'NNS'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('more', 'JJR'), ('of', 'IN'), ('a', 'DT'), ('snap', 'NN'), ('it', 'PRP'), ('on', 'IN'), ('/', 'NNP'), ('snap', 'VBD'), ('it', 'PRP'), ('off', 'RP'), ('.', '.'), ('Other', 'JJ'), ('than', 'IN'), ('that', 'IN'), ('it', 'PRP'), ('does', 'VBZ'), ('help', 'VB'), ('protect', 'VB'), ('it', 'PRP'), ('from', 'IN'), ('dust', 'NN'), ('and', 'CC'), ('getting', 'VBG'), ('the', 'DT'), ('screen', 'NN'), ('scratched', 'VBN'), ('.', '.')]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54FRdTfl-TLp",
        "colab_type": "code",
        "outputId": "4012a507-edc7-4247-fa84-facf3e1e7236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#WordNetLemmatizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJu-VTFF_An5",
        "colab_type": "code",
        "outputId": "0d87f60e-80d4-4349-8d85-65da6db21fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "lemmatizer = WordNetLemmatizer() \n",
        "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(df.reviewText[20])])\n",
        "print(lemmatized_output)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This calculator doe the job for what I need . No battery needed and it is solar powered . Only problem I have is the cover case . It is not slide in / slide out cover case like most calculator . It is more of a snap it on / snap it off . Other than that it doe help protect it from dust and getting the screen scratched .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu_jBOWuBjhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finding adjectives in postag\n",
        "pos_tag1=nltk.pos_tag(nltk.word_tokenize(df.reviewText[10]))\n",
        "adj=[]\n",
        "for i in pos_tag1:\n",
        "    if i[1] == 'JJ':\n",
        "      adj.append(i[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exRLXZ8rCol_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "2d0d9afa-36b3-4bff-9d40-e5b8137d458c"
      },
      "source": [
        "adj"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['few',\n",
              " 'carpeted',\n",
              " 'Large',\n",
              " 'easy',\n",
              " 'nice',\n",
              " 'hard',\n",
              " 'soft',\n",
              " 'Large',\n",
              " 'easy',\n",
              " 'good',\n",
              " 'everyday',\n",
              " 'basic']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    }
  ]
}
